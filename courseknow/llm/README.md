使用 LLM 进行对话，辅助进行知识点抽取

一、模型的 API 服务

 - Qwen Turbo
 - Qwen Max


二、本地部署模型

